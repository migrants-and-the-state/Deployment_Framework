[paths]
examples = null

[nlp]
lang = "en"
pipeline = ["llm"]
batch_size = 128

[components]

[components.llm]
factory = "llm"

# uncomment lines 16,17 to run with openai. Comment 16,17 and uncomment 18,19,20,21 to run local llms
[components.llm.model]
# @llm_models = "spacy.GPT-3-5.v1"
# name = "gpt-3.5-turbo" 
@llm_models = "langchain.Ollama.v1"
name= "llama3.1" 
query = {"@llm_queries": "spacy.CallLangChain.v1"} 
config = {"temperature": 0.0} 


# [components.llm.model.config_init]
# offload_folder = "."
# torch_dtype = "half"

[components.llm.task]
@llm_tasks = "spacy.NER.v2"
# labels = PERSON,ORGANISATION,LOCATION
labels = EMPLOYER,OCCUPATION,STATE_CITY,COUNTRY,YEAR,REVISION_DATE,OMB_NUMBER,FORM_NUMBER,NATIONALITY,EMPLOYER_ADDRESS,PARENT_COUNTRY,PARENT_STATE_CITY,MARRIAGE_DATE,MARRIAGE_TERMINATION_DATE,MARRIAGE_PLACE

[components.llm.task.examples]
@misc = "spacy.FewShotReader.v1"
path = ${paths.examples}

[components.llm.task.normalizer]
@misc = "spacy.LowercaseNormalizer.v1"

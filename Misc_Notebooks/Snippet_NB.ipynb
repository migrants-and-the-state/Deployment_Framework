{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dict containing Afile data with urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# import cv2\n",
    "import urllib.request\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Goals  - Done\n",
    "1. iterate through index.json\n",
    "  1. just iterate through the keys\n",
    "  2. (full url contains the whole thing)\n",
    "2. check image downloads and see if you're able to visualize the images\n",
    "3. try running a prediction run to see if its working properly\n",
    "\n",
    "'''\n",
    "\n",
    "index_url = \"https://nyu-dss.github.io/aperitiiif-batch-migrants-state/index.json\"\n",
    "resp = requests.get(index_url).json()\n",
    "\n",
    "\n",
    "'''\n",
    "lets create a structure:\n",
    "  a-file id\n",
    "    page\n",
    "      full_url\n",
    "      pageno\n",
    "'''\n",
    "aline_dict = dict()\n",
    "\n",
    "for page in resp:\n",
    "  info = page['id'].split('_')\n",
    "  if info[0] not in aline_dict:\n",
    "    aline_dict[info[0]] = dict(pages=[])\n",
    "    if 'redacted' in aline_dict[info[0]] and len(info) == 2:\n",
    "      print(\"looks like pdf has redacted and non redacted\",info)\n",
    "    if len(info) == 3 and info[1] == 'redacted':\n",
    "      aline_dict[info[0]]['redacted'] = True\n",
    "    else:\n",
    "      aline_dict[info[0]]['redacted'] = False\n",
    "  pno = int(info[-1])\n",
    "  if pno in aline_dict[info[0]]:\n",
    "    print(\"Pno present\",info)\n",
    "  else:\n",
    "    aline_dict[info[0]]['pages'].append({'pno' : pno, 'full_url':page['full_url']})\n",
    "\n",
    "index_list = list()\n",
    "for aline in aline_dict.keys():\n",
    "  redacted = aline_dict[aline]['redacted']\n",
    "  for page in aline_dict[aline]['pages']:\n",
    "    index_list.append({'redacted':redacted,'pno':page['pno'],'full_url':page['full_url'],'afile':aline})\n",
    "\n",
    "len(index_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR WRiting Code with Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract', region_name='us-east-1')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Your S3 bucket name\n",
    "bucket_name = 'mats-datadump'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "\n",
    "def upload_image_to_s3(image_url):\n",
    "    # Download the image\n",
    "    response = requests.get(image_url)\n",
    "    image_key = image_url.split('/')[5]  # Assume the image file name is the last segment of the URL\n",
    "\n",
    "    # Upload to S3\n",
    "    s3.put_object(Bucket=bucket_name, Key=image_key, Body=response.content)\n",
    "    return image_key\n",
    "\n",
    "def delete_image_from_s3(bucket_name, object_key):\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.delete_object(Bucket=bucket_name, Key=object_key)\n",
    "    # print(f\"Deleted {object_key} from {bucket_name}\")\n",
    "\n",
    "def dump_json(file_url, json_file):\n",
    "    savepath = os.getcwd() + f\"/ocr_dump/{file_url.split('/')[5]}_textract.json\"\n",
    "    with open(savepath, 'w') as outfile:\n",
    "        json.dump(json_file, outfile)\n",
    "    return savepath\n",
    "\n",
    "\n",
    "def invoke_textract(image_key):\n",
    "    response = textract.detect_document_text(\n",
    "        Document={'S3Object': {'Bucket': bucket_name, 'Name': image_key}}\n",
    "    )\n",
    "    # response = textract.analyze_document(\n",
    "    #     Document={'S3Object': {'Bucket': bucket_name, 'Name': image_key},\n",
    "    #     },FeatureTypes=[\n",
    "    #     'TABLES','FORMS','SIGNATURES','LAYOUT',\n",
    "    # ]\n",
    "    # )\n",
    "    return response \n",
    "\n",
    "\n",
    "def detect_text_only(response):\n",
    "    # Extract text from blocks\n",
    "    text_blocks = [block['Text'] for block in response['Blocks'] if block['BlockType'] == 'LINE']\n",
    "    detected_text = ' '.join(text_blocks)\n",
    "    return detected_text\n",
    "\n",
    "\n",
    "def detect_text_from_s3(image_key, text_only = False):\n",
    "    # Call DetectDocumentText API\n",
    "    response = invoke_textract(image_key = image_key)\n",
    "\n",
    "    # Extract text and its position from blocks\n",
    "    text_data = []\n",
    "    detected_text = list()\n",
    "    for block in response['Blocks']:\n",
    "        if block['BlockType'] == 'LINE':\n",
    "            text = block['Text']\n",
    "            detected_text.append(text)\n",
    "            if not text_only:\n",
    "                bounding_box = block.get('Geometry', {}).get('BoundingBox', {})\n",
    "                polygon = block.get('Geometry', {}).get('Polygon', [])\n",
    "                text_data.append({\n",
    "                    'Text': text,\n",
    "                    'BoundingBox': bounding_box,\n",
    "                    'Polygon': polygon\n",
    "                })\n",
    "\n",
    "    return ' '.join(detected_text), text_data, response\n",
    "\n",
    "def invoke_textract_on_url(image_url):\n",
    "    '''\n",
    "    1. gets image url\n",
    "    2. uploads to s3\n",
    "    3. invokes textract and saves the results locally\n",
    "    4. deletes files from s3 (for storage concerns)\n",
    "    '''\n",
    "\n",
    "    image_key = upload_image_to_s3(image_url)\n",
    "    detected_text, text_coords, response = detect_text_from_s3(image_key=image_key, text_only=False)\n",
    "    delete_image_from_s3(bucket_name, image_key)\n",
    "    return detected_text, text_coords, response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "# df = list()\n",
    "\n",
    "# for i in tqdm(range(20)):\n",
    "#     url = index_list[i]['full_url']\n",
    "#     detected_text, text_coords, response = invoke_textract_on_url(url)\n",
    "#     savepath = dump_json(url, response)\n",
    "#     df.append([index_list[i]['afile'], index_list[i]['pno'], index_list[i]['redacted'], index_list[i]['full_url'], detected_text, savepath])\n",
    "\n",
    "# df = pd.DataFrame(df, columns = ['Afile', 'Page', 'Is_Redacted', 'url', 'Detected Text', 'Ocr_Dump_path'])\n",
    "\n",
    "# print(f\"Time taken {time.time() - st}\")\n",
    "\n",
    "\n",
    "def invoke_ocr_serial(i):\n",
    "    try:\n",
    "        time.sleep(0.3)\n",
    "        url = index_list[i]['full_url']\n",
    "        detected_text, text_coords, response = invoke_textract_on_url(url)\n",
    "        savepath = dump_json(url, response)\n",
    "        return [i, index_list[i]['afile'], index_list[i]['pno'], index_list[i]['redacted'], index_list[i]['full_url'], detected_text, savepath]\n",
    "    except Exception as e:\n",
    "        print(i, \"Skipped over error\",e)\n",
    "        return [i, index_list[i]['afile'], index_list[i]['pno'], index_list[i]['redacted'], index_list[i]['full_url'], None, None]\n",
    "    \n",
    "for st in range(1000, len(index_list), 1000):\n",
    "    start = time.time() \n",
    "    ed = min(len(index_list),st+1000)\n",
    "    print(\"Running OCR FOR:\",st,ed)\n",
    "    results = Parallel(n_jobs=20, backend='threading')(delayed(invoke_ocr_serial)(i) for i in range(st,ed))\n",
    "    df = pd.DataFrame(results, columns = ['idx', 'Afile', 'Page', 'Is_Redacted', 'url', 'Detected Text', 'Ocr_Dump_path'])\n",
    "\n",
    "    print(\"Time taken\",time.time() - start)\n",
    "    df.to_csv(f\"ocr_dump_{st}_{ed}.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import re\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'ocr_dump_(\\d+)_', filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "csv_files = []\n",
    "for f in os.listdir():\n",
    "    if 'ocr_dump_' in f:\n",
    "        csv_files.append(os.getcwd() + f'/{f}')\n",
    "\n",
    "\n",
    "# Sort filenames by the extracted number\n",
    "sorted_filenames = sorted(csv_files, key=extract_number)\n",
    "sorted_filenames\n",
    "\n",
    "\n",
    "# Set the path where the CSV files are located\n",
    "path_to_csv_files = Path(\"./\")\n",
    "\n",
    "# List all CSV files in the directory\n",
    "# csv_files = list(path_to_csv_files.glob('ocr_dump_*.csv'))\n",
    "\n",
    "# Read and concatenate all CSV files into one dataframe\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in sorted_filenames])\n",
    "\n",
    "# Save the combined CSV to a single file\n",
    "combined_csv_path = path_to_csv_files / \"combined_csv.csv\"\n",
    "combined_csv.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "# Provide the path to the saved combined CSV file\n",
    "combined_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import shutil\n",
    "import PIL\n",
    "import torch\n",
    "from torch import nn\n",
    "# from torchvision import transforms\n",
    "# from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL.Image as Image\n",
    "import time\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "def download_preprocess_image(url):\n",
    "    image = None\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # Set timeout as per your requirement\n",
    "        response.raise_for_status()  # This will raise an exception for HTTP errors\n",
    "         # If the request was successful, proceed with processing the image\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "        print(\"Retrying\")# Handle HTTP errors like 502\n",
    "\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, timeout=5)  # Set timeout as per your requirement\n",
    "        response.raise_for_status()  # This will raise an exception for HTTP errors\n",
    "         # If the request was successful, proceed with processing the image\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")  # Handle other errors like timeouts\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "def get_matrix(MODEL_PATH, DATA_PATH):\n",
    "\n",
    "    return embeddings,filenames\n",
    "\n",
    "\n",
    "class TSNE_visualiser: \n",
    "    def __init__(self, feature_list, filenames):\n",
    "        # '''\n",
    "        # params:\n",
    "        # feature_list : Embeddings list\n",
    "        # filenames: filenames for the images in the embeddings list\n",
    "        # '''\n",
    "        self.feature_list = feature_list\n",
    "        self.filenames = filenames\n",
    "        \n",
    "    # return train_data_reshaped, labels, feature_list\n",
    "\n",
    "    def fit_tsne(self, perplexity= 30, n_jobs= 4):\n",
    "    # '''\n",
    "    # Fits TSNE for the input embeddings\n",
    "    # feature_list: ssl embeddings\n",
    "    # perplexity : hyperparameter that determines how many images are close to each other in a cluster\n",
    "    # n_jobs : number of jobs to be run concurrently. \n",
    "    # '''\n",
    "        n_components = 2\n",
    "        verbose = 1\n",
    "        perplexity = perplexity\n",
    "        n_iter = 1000\n",
    "        metric = 'euclidean'\n",
    "        n_jobs= n_jobs\n",
    "\n",
    "        time_start = time.time()\n",
    "        tsne_results = TSNE(n_components=n_components,\n",
    "                            verbose=verbose,\n",
    "                            perplexity=perplexity,\n",
    "                            n_iter=n_iter,\n",
    "                            n_jobs= n_jobs,\n",
    "                            metric=metric).fit_transform(self.feature_list)\n",
    "\n",
    "        print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))\n",
    "        return tsne_results\n",
    "    \n",
    "    def scatter_plot(self, tsne_results):\n",
    "    # '''\n",
    "    # Plots a scatter plot for the given TSNE fit variable\n",
    "    # '''\n",
    "        # le = LabelEncoder()\n",
    "        # class_labels = le.fit_transform(labels)\n",
    "        color_map = plt.cm.get_cmap('tab20b_r')\n",
    "        scatter_plot = plt.scatter(tsne_results[:, 0],\n",
    "                                tsne_results[:, 1],\n",
    "                                # c=class_labels,\n",
    "                                cmap=color_map)\n",
    "        \n",
    "        plt.colorbar(scatter_plot)\n",
    "        plt.title('TSNE of Embeddings');\n",
    "        fname = './TSNE_Scatter.png'\n",
    "        plt.savefig(fname)\n",
    "\n",
    "    def plot_images_in_2d(self, x, y, image_vectors, axis=None, zoom=1):\n",
    "    # '''\n",
    "    # Helper function, do not call. \n",
    "    # params:\n",
    "    # x, y : TSNE variables\n",
    "    # image_vectors: images in the dataset\n",
    "    # '''\n",
    "        if axis is None:\n",
    "            axis = plt.gca()\n",
    "        x, y = np.atleast_1d(x, y)\n",
    "        for x0, y0, image_path in zip(x, y, image_vectors):\n",
    "            image = download_preprocess_image(index_list[image_path]['full_url'])\n",
    "            image.thumbnail((300, 300), Image.LANCZOS)\n",
    "            img = OffsetImage(image, zoom=zoom)\n",
    "            anno_box = AnnotationBbox(img, (x0, y0),\n",
    "                                    xycoords='data',\n",
    "                                    frameon=False)\n",
    "            axis.add_artist(anno_box)\n",
    "        axis.update_datalim(np.column_stack([x, y]))\n",
    "        axis.autoscale()\n",
    "\n",
    "    def show_tsne(self, x, y, images):\n",
    "      \n",
    "      fig, axis = plt.subplots()\n",
    "      fig.set_size_inches(22, 22, forward=True)\n",
    "      self.plot_images_in_2d(x, y, images, zoom=0.3, axis=axis)\n",
    "      fname = './TSNE_regplot1.png'\n",
    "      plt.savefig(fname)\n",
    "\n",
    "    def tsne_to_grid_plotter_manual(self, x, y, selected_filenames):\n",
    "      # '''\n",
    "      # TSNE visualiser with evenly spaced out images\n",
    "      # params:\n",
    "      # x, y : TSNE variables\n",
    "      # selected_filenames: images in the dataset\n",
    "      # '''\n",
    "          S = 2000\n",
    "          s = 100\n",
    "          x = (x - min(x)) / (max(x) - min(x))\n",
    "          y = (y - min(y)) / (max(y) - min(y))\n",
    "          x_values = []\n",
    "          y_values = []\n",
    "          filename_plot = []\n",
    "          x_y_dict = {}\n",
    "          for i, image_path in enumerate(selected_filenames):\n",
    "              a = np.ceil(x[i] * (S - s))\n",
    "              b = np.ceil(y[i] * (S - s))\n",
    "              a = int(a - np.mod(a, s))\n",
    "              b = int(b - np.mod(b, s))\n",
    "              if str(a) + \"|\" + str(b) in x_y_dict:\n",
    "                  continue\n",
    "              x_y_dict[str(a) + \"|\" + str(b)] = 1\n",
    "              x_values.append(a)\n",
    "              y_values.append(b)\n",
    "              filename_plot.append(image_path)\n",
    "          fig, axis = plt.subplots()\n",
    "          fig.set_size_inches(50, 50, forward=True)\n",
    "          self.plot_images_in_2d(x_values, y_values, filename_plot, zoom=.58, axis=axis)\n",
    "          fname = './TSNE_GridPlot.png'\n",
    "          plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE_visualiser(embeddings[:1000], [i for i in range(len(embeddings[:1000]))])\n",
    "result = tsne.fit_tsne()\n",
    "\n",
    "tsne.show_tsne(result[:, 0], result[:, 1], tsne.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.tsne_to_grid_plotter_manual(result[:, 0], result[:, 1], tsne.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output logic\n",
    "  1. take an image\n",
    "  2. retrieve n similar images\n",
    "  3. run it through model and plot those images side by side\n",
    "\n",
    "'''\n",
    "def query_faiss(index, query_vector,k,dims):\n",
    "    query_vector = query_vector.reshape(1,dims)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "\n",
    "    print(\"Indices of nearest neighbors:\", indices)\n",
    "    print(\"Distances of nearest neighbors:\", distances)\n",
    "    return distances, indices\n",
    "\n",
    "def plot_images(indices,source_idx=None):\n",
    "    overlaps = list()\n",
    "    # for idx in indices[0]:\n",
    "    #   image = download_preprocess_image(indexed_urls[idx]['full_url'])\n",
    "    #   _, _, _, overlap, _ = predict_docufcn(image)\n",
    "    #   overlaps.append(overlap)\n",
    "    if source_idx is None:\n",
    "        fig, axs = plt.subplots(1, len(indices[0]), figsize=(30, 30))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, len(indices[0])+1, figsize=(30, 30))\n",
    "        axs[0].imshow(download_preprocess_image(index_list[source_idx]['full_url']))\n",
    "        axs[0].set_title(f\"Source Image\")\n",
    "    for i in range(len(indices[0])):\n",
    "        axs[i+1].imshow(download_preprocess_image(index_list[indices[0][i]]['full_url']))\n",
    "        axs[i+1].set_title(f\"Retrieved Image {i+1}\")\n",
    "\n",
    "    for ax in axs:\n",
    "      ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings\n",
    "reference_shape = vectors[0].shape\n",
    "\n",
    "# Initialize a list to store the indices of elements with different shapes\n",
    "different_shape_indices = []\n",
    "for i, arr in enumerate(vectors[1:], start=1):\n",
    "    # Compare the shape of the current element with the reference shape\n",
    "    if arr is None:\n",
    "        different_shape_indices.append(i)\n",
    "\n",
    "print(different_shape_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "dims = 512\n",
    "\n",
    "def create_l2_index(dims,vectors):\n",
    "    index = faiss.IndexFlatL2(dims)  # Using a flat (brute-force) index\n",
    "\n",
    "    index.add(np.array(vectors))\n",
    "\n",
    "    query_vector = vectors[3].reshape(1,dims)\n",
    "    k = 5\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "\n",
    "    print(\"Indices of nearest neighbors:\", indices)\n",
    "    print(\"Distances of nearest neighbors:\", distances)\n",
    "    \n",
    "    return index\n",
    "\n",
    "\n",
    "def normalize_vectors(vectors):\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    return vectors / np.maximum(norms, 1e-6)\n",
    "\n",
    "\n",
    "def create_cosine_index(dims, vectors):\n",
    "    index = faiss.IndexFlatIP(dims)  # 'IP' stands for Inner Product\n",
    "\n",
    "    # Add vectors to the index\n",
    "    index.add(np.array(vectors))\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write as CSV To visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_csv(indices, source_idx=None):\n",
    "    return [index_list[indices[0][i]]['full_url'] for i in range(len(indices[0]))]\n",
    "\n",
    "outputcsv = list()\n",
    "for i in range(len(vectors_cosine[:1000])):\n",
    "    distances, indices = query_faiss(index_cosine, vectors[i],6,dims)\n",
    "    outputcsv.append(add_to_csv(indices))\n",
    "outputcsv = pd.DataFrame(outputcsv,columns=[\"Source\"]+[f\"Retrieved Image {i}\" for i in range(1,len(indices[0]))])\n",
    "outputcsv.to_csv('textract_retrieval.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot as Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = vectors[0].shape[0]\n",
    "vectors_cosine = normalize_vectors(vectors)\n",
    "index_cosine = create_cosine_index(dims,vectors)\n",
    "for i in range(len(vectors_cosine)):\n",
    "    distances, indices = query_faiss(index_cosine, vectors[i],6,dims)\n",
    "    plot_images(indices,i)\n",
    "    if i == 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
